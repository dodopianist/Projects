{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f72250f",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b27e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbce9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_parquet('train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e921c236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>− Scope 3: Optional scope that includes indire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Group is not aware of any noise pollution ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global climate change could exacerbate certain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Setting an investment horizon is part and parc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Climate change the physical impacts of climate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  − Scope 3: Optional scope that includes indire...      1\n",
       "1  The Group is not aware of any noise pollution ...      0\n",
       "2  Global climate change could exacerbate certain...      0\n",
       "3  Setting an investment horizon is part and parc...      0\n",
       "4  Climate change the physical impacts of climate...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_text.shape)\n",
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d971ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cffe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sustainable strategy ‘red lines’ For our susta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Verizon’s environmental, health and safety man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2019, the Company closed a series of transa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In December 2020, the AUC approved the Electri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally, there is a reputational risk linked t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Sustainable strategy ‘red lines’ For our susta...      0\n",
       "1  Verizon’s environmental, health and safety man...      1\n",
       "2  In 2019, the Company closed a series of transa...      1\n",
       "3  In December 2020, the AUC approved the Electri...      0\n",
       "4  Finally, there is a reputational risk linked t...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_text.shape)\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908fbdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    163\n",
       "0    106\n",
       "2     51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685f60f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04572de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a84a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64933ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \n",
    "    df_new = df.copy()\n",
    "    tokenise_text = [nltk.word_tokenize(text.lower().replace('’', \"'\")) for text in df['text']]\n",
    "    stop_words = [item for item in ENGLISH_STOP_WORDS]\n",
    "    punctuations = [item for item in string.punctuation]\n",
    "    punctuations.append('−')\n",
    "    punctuations.append('—')\n",
    "    punctuations.append('‘')\n",
    "    punctuations.append('``')\n",
    "    punctuations.append(\"''\")\n",
    "    punctuations.append('\"\"')\n",
    "    punctuations.append('•')\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    stemmed_text_wo_punct = []\n",
    "    for text in tokenise_text:\n",
    "        \n",
    "        pos_tagged = pos_tag(text)\n",
    "        stemmed_word = [\n",
    "            lemmatizer.lemmatize(word, pos = get_wordnet_pos(pos))\n",
    "            for word, pos in pos_tagged if not word in stop_words\n",
    "        ]\n",
    "        stemmed_text.append(stemmed_word)\n",
    "        \n",
    "        stemmed_word_wo_punct = [\n",
    "            word for word in stemmed_word if not word in punctuations\n",
    "        ]\n",
    "        stemmed_text_wo_punct.append(stemmed_word_wo_punct)\n",
    "    \n",
    "    df_new['processed'] = stemmed_text\n",
    "    df_new['processed_wo_punct'] = stemmed_text_wo_punct\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0764ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_processed = preprocessing(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05fad724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>− Scope 3: Optional scope that includes indire...</td>\n",
       "      <td>1</td>\n",
       "      <td>[−, scope, 3, :, optional, scope, include, ind...</td>\n",
       "      <td>[scope, 3, optional, scope, include, indirect,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Group is not aware of any noise pollution ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[group, aware, noise, pollution, negatively, i...</td>\n",
       "      <td>[group, aware, noise, pollution, negatively, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global climate change could exacerbate certain...</td>\n",
       "      <td>0</td>\n",
       "      <td>[global, climate, change, exacerbate, certain,...</td>\n",
       "      <td>[global, climate, change, exacerbate, certain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Setting an investment horizon is part and parc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[set, investment, horizon, parcel, policy, foc...</td>\n",
       "      <td>[set, investment, horizon, parcel, policy, foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Climate change the physical impacts of climate...</td>\n",
       "      <td>0</td>\n",
       "      <td>[climate, change, physical, impact, climate, c...</td>\n",
       "      <td>[climate, change, physical, impact, climate, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  − Scope 3: Optional scope that includes indire...      1   \n",
       "1  The Group is not aware of any noise pollution ...      0   \n",
       "2  Global climate change could exacerbate certain...      0   \n",
       "3  Setting an investment horizon is part and parc...      0   \n",
       "4  Climate change the physical impacts of climate...      0   \n",
       "\n",
       "                                           processed  \\\n",
       "0  [−, scope, 3, :, optional, scope, include, ind...   \n",
       "1  [group, aware, noise, pollution, negatively, i...   \n",
       "2  [global, climate, change, exacerbate, certain,...   \n",
       "3  [set, investment, horizon, parcel, policy, foc...   \n",
       "4  [climate, change, physical, impact, climate, c...   \n",
       "\n",
       "                                  processed_wo_punct  \n",
       "0  [scope, 3, optional, scope, include, indirect,...  \n",
       "1  [group, aware, noise, pollution, negatively, i...  \n",
       "2  [global, climate, change, exacerbate, certain,...  \n",
       "3  [set, investment, horizon, parcel, policy, foc...  \n",
       "4  [climate, change, physical, impact, climate, c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_text.shape)\n",
    "train_text_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c27489",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_processed = preprocessing(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2a517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sustainable strategy ‘red lines’ For our susta...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sustainable, strategy, ‘, red, line, ', susta...</td>\n",
       "      <td>[sustainable, strategy, red, line, sustainable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Verizon’s environmental, health and safety man...</td>\n",
       "      <td>1</td>\n",
       "      <td>[verizon, 's, environmental, ,, health, safety...</td>\n",
       "      <td>[verizon, 's, environmental, health, safety, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2019, the Company closed a series of transa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2019, ,, company, close, series, transaction,...</td>\n",
       "      <td>[2019, company, close, series, transaction, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In December 2020, the AUC approved the Electri...</td>\n",
       "      <td>0</td>\n",
       "      <td>[december, 2020, ,, auc, approve, electricity,...</td>\n",
       "      <td>[december, 2020, auc, approve, electricity, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally, there is a reputational risk linked t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[finally, ,, reputational, risk, link, possibi...</td>\n",
       "      <td>[finally, reputational, risk, link, possibilit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Sustainable strategy ‘red lines’ For our susta...      0   \n",
       "1  Verizon’s environmental, health and safety man...      1   \n",
       "2  In 2019, the Company closed a series of transa...      1   \n",
       "3  In December 2020, the AUC approved the Electri...      0   \n",
       "4  Finally, there is a reputational risk linked t...      0   \n",
       "\n",
       "                                           processed  \\\n",
       "0  [sustainable, strategy, ‘, red, line, ', susta...   \n",
       "1  [verizon, 's, environmental, ,, health, safety...   \n",
       "2  [2019, ,, company, close, series, transaction,...   \n",
       "3  [december, 2020, ,, auc, approve, electricity,...   \n",
       "4  [finally, ,, reputational, risk, link, possibi...   \n",
       "\n",
       "                                  processed_wo_punct  \n",
       "0  [sustainable, strategy, red, line, sustainable...  \n",
       "1  [verizon, 's, environmental, health, safety, m...  \n",
       "2  [2019, company, close, series, transaction, re...  \n",
       "3  [december, 2020, auc, approve, electricity, di...  \n",
       "4  [finally, reputational, risk, link, possibilit...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_text.shape)\n",
    "test_text_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed016b1e",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332de75",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78ff2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16e27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c39f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_training(df):\n",
    "        \n",
    "    bow_train_counts = count_vect.fit_transform([' '.join(text) for text in df['processed_wo_punct']])\n",
    "    transformer_train = TfidfTransformer().fit(bow_train_counts)\n",
    "    bow_train_tfidf = transformer_train.transform(bow_train_counts)\n",
    "    bagofwords = pd.DataFrame.sparse.from_spmatrix(\n",
    "        bow_train_tfidf, columns = count_vect.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    bagofwords = bagofwords.add_prefix('bow_')\n",
    "    \n",
    "    return bagofwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e45ca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5145)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow = bag_of_words_training(train_text_processed)\n",
    "train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bdb2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_testing(df):\n",
    "        \n",
    "    bow_test_counts = count_vect.transform([' '.join(text) for text in df['processed_wo_punct']])\n",
    "    transformer_test = TfidfTransformer().fit(bow_test_counts)\n",
    "    bow_test_tfidf = transformer_test.transform(bow_test_counts)\n",
    "    bagofwords = pd.DataFrame.sparse.from_spmatrix(\n",
    "        bow_test_tfidf, columns = count_vect.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    bagofwords = bagofwords.add_prefix('bow_')\n",
    "    \n",
    "    return bagofwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c78cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 5145)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bow = bag_of_words_testing(test_text_processed)\n",
    "test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2d784",
   "metadata": {},
   "source": [
    "## Word2Vec (Doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9df9d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f07f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_text_processed['processed_wo_punct'])]\n",
    "model = Doc2Vec(documents, vector_size = 100, window = 2, min_count = 1, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca7d6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = []\n",
    "for text in train_text_processed['processed_wo_punct']:\n",
    "    vector = model.infer_vector(text)\n",
    "    train_vectors.append(vector)\n",
    "train_d2v = pd.DataFrame(train_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8ee651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e48c21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "for text in test_text_processed['processed_wo_punct']:\n",
    "    vector = model.infer_vector(text)\n",
    "    test_vectors.append(vector)\n",
    "test_d2v = pd.DataFrame(test_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "140e5ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_d2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e0f41",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c5afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17fb1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee79da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef1d4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_score = []\n",
    "neu_score = []\n",
    "pos_score = []\n",
    "compound_score = []\n",
    "\n",
    "for text in train_text_processed['text']:\n",
    "    neg = sid.polarity_scores(text)['neg']\n",
    "    neg_score.append(neg)\n",
    "    neu = sid.polarity_scores(text)['neu']\n",
    "    neu_score.append(neu)\n",
    "    pos = sid.polarity_scores(text)['pos']\n",
    "    pos_score.append(pos)\n",
    "    compound = sid.polarity_scores(text)['compound']\n",
    "    compound_score.append(compound)\n",
    "\n",
    "train_sentiment['neg'] = neg_score\n",
    "train_sentiment['neu'] = neu_score\n",
    "train_sentiment['pos'] = pos_score\n",
    "train_sentiment['compound'] = compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de9d80b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07eaed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ca6edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_score = []\n",
    "neu_score = []\n",
    "pos_score = []\n",
    "compound_score = []\n",
    "\n",
    "for text in test_text_processed['text']:\n",
    "    neg = sid.polarity_scores(text)['neg']\n",
    "    neg_score.append(neg)\n",
    "    neu = sid.polarity_scores(text)['neu']\n",
    "    neu_score.append(neu)\n",
    "    pos = sid.polarity_scores(text)['pos']\n",
    "    pos_score.append(pos)\n",
    "    compound = sid.polarity_scores(text)['compound']\n",
    "    compound_score.append(compound)\n",
    "\n",
    "test_sentiment['neg'] = neg_score\n",
    "test_sentiment['neu'] = neu_score\n",
    "test_sentiment['pos'] = pos_score\n",
    "test_sentiment['compound'] = compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f6f8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7ce46",
   "metadata": {},
   "source": [
    "## Concat Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f59ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.concat([train_bow, train_d2v, train_sentiment], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1609d39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5249)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10bab4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_vector = train_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bc49439",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = pd.concat([test_bow, test_d2v, test_sentiment], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d37d9b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 5249)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c4071df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_vector = test_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964238dc",
   "metadata": {},
   "source": [
    "# Model Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a4d290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1066f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec295771",
   "metadata": {},
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adb4f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3b01279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy = \"most_frequent\").fit(train_feature_vector, train_text['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c89a91",
   "metadata": {},
   "source": [
    "### Cross-Validation (Train Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2ef8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_scores = []\n",
    "\n",
    "for train_index, val_index in kfold.split(train_text_processed):\n",
    "    \n",
    "    cross_train = train_text_processed.iloc[train_index].reset_index(drop = True)\n",
    "    cross_val = train_text_processed.iloc[val_index].reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    train_bow = bag_of_words_training(cross_train)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(cross_train['processed_wo_punct'])]\n",
    "    model = Doc2Vec(documents, vector_size = 100, window = 2, min_count = 1, workers = 4)\n",
    "    train_vectors = []\n",
    "    for text in cross_train['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        train_vectors.append(vector)\n",
    "    train_d2v = pd.DataFrame(train_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    train_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_train['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    train_sentiment['neg'] = neg_score\n",
    "    train_sentiment['neu'] = neu_score\n",
    "    train_sentiment['pos'] = pos_score\n",
    "    train_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_train = pd.concat([train_bow, train_d2v, train_sentiment], axis = 1)\n",
    "    features_train_vector = features_train.to_numpy()\n",
    "    \n",
    "    \n",
    "    test_bow = bag_of_words_testing(cross_val)\n",
    "    \n",
    "    test_vectors = []\n",
    "    for text in cross_val['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        test_vectors.append(vector)\n",
    "    test_d2v = pd.DataFrame(test_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    test_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_val['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    test_sentiment['neg'] = neg_score\n",
    "    test_sentiment['neu'] = neu_score\n",
    "    test_sentiment['pos'] = pos_score\n",
    "    test_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_test = pd.concat([test_bow, test_d2v, test_sentiment], axis = 1)\n",
    "    features_test_vector = features_test.to_numpy()\n",
    "    \n",
    "    model = DummyClassifier(strategy = \"most_frequent\").fit(features_train_vector, cross_train['label'])\n",
    "    y_pred = model.predict(features_test_vector)\n",
    "    score = accuracy_score(cross_val['label'], y_pred)\n",
    "    \n",
    "    dummy_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9e8e6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40800000000000003"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dummy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "652641da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0304611998713117"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((np.mean(dummy_scores) * (1 - np.mean(dummy_scores))) / len(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6c44b",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddb3ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = dummy_clf.predict(test_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9a86f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_dummy = dummy_clf.score(test_feature_vector, test_text['label'])\n",
    "confusion_dummy = confusion_matrix(test_text['label'], y_pred_dummy)\n",
    "classification_dummy = classification_report(test_text['label'], y_pred_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4917a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.509375"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dad93a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dummy_interval = 1.96 * sqrt((accuracy_dummy * (1 - accuracy_dummy)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e865b7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054774034661022326"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dummy_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b7eb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 106   0]\n",
      " [  0 163   0]\n",
      " [  0  51   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae613bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       106\n",
      "           1       0.51      1.00      0.67       163\n",
      "           2       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.51       320\n",
      "   macro avg       0.17      0.33      0.22       320\n",
      "weighted avg       0.26      0.51      0.34       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e33c45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04115708322998606"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.17 * (1 - 0.17)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02aa738b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05151995244563022"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.33 * (1 - 0.33)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ee4e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04538786181348489"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.22 * (1 - 0.22)) / len(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f70ad2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c52fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f55a458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression().fit(train_feature_vector, train_text['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22372bbe",
   "metadata": {},
   "source": [
    "### Cross-Validation (Train Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecea4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_scores = []\n",
    "\n",
    "for train_index, val_index in kfold.split(train_text_processed):\n",
    "    \n",
    "    cross_train = train_text_processed.iloc[train_index].reset_index(drop = True)\n",
    "    cross_val = train_text_processed.iloc[val_index].reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    train_bow = bag_of_words_training(cross_train)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(cross_train['processed_wo_punct'])]\n",
    "    model = Doc2Vec(documents, vector_size = 100, window = 2, min_count = 1, workers = 4)\n",
    "    train_vectors = []\n",
    "    for text in cross_train['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        train_vectors.append(vector)\n",
    "    train_d2v = pd.DataFrame(train_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    train_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_train['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    train_sentiment['neg'] = neg_score\n",
    "    train_sentiment['neu'] = neu_score\n",
    "    train_sentiment['pos'] = pos_score\n",
    "    train_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_train = pd.concat([train_bow, train_d2v, train_sentiment], axis = 1)\n",
    "    features_train_vector = features_train.to_numpy()\n",
    "    \n",
    "    \n",
    "    test_bow = bag_of_words_testing(cross_val)\n",
    "    \n",
    "    test_vectors = []\n",
    "    for text in cross_val['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        test_vectors.append(vector)\n",
    "    test_d2v = pd.DataFrame(test_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    test_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_val['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    test_sentiment['neg'] = neg_score\n",
    "    test_sentiment['neu'] = neu_score\n",
    "    test_sentiment['pos'] = pos_score\n",
    "    test_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_test = pd.concat([test_bow, test_d2v, test_sentiment], axis = 1)\n",
    "    features_test_vector = features_test.to_numpy()\n",
    "    \n",
    "    model = LogisticRegression().fit(features_train_vector, cross_train['label'])\n",
    "    y_pred = model.predict(features_test_vector)\n",
    "    score = accuracy_score(cross_val['label'], y_pred)\n",
    "    \n",
    "    LR_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0de62c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(LR_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17604bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02761242824526666"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((np.mean(LR_scores) * (1 - np.mean(LR_scores))) / len(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758f64a",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1468dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR = LR_clf.predict(test_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a95de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_LR = LR_clf.score(test_feature_vector, test_text['label'])\n",
    "confusion_LR = confusion_matrix(test_text['label'], y_pred_LR)\n",
    "classification_LR = classification_report(test_text['label'], y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22047178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee6fb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_LR_interval = 1.96 * sqrt((accuracy_LR * (1 - accuracy_LR)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b8b6953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046835979071082466"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_LR_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53cff7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 88  14   4]\n",
      " [ 21 124  18]\n",
      " [  2  18  31]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "843ded15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       106\n",
      "           1       0.79      0.76      0.78       163\n",
      "           2       0.58      0.61      0.60        51\n",
      "\n",
      "    accuracy                           0.76       320\n",
      "   macro avg       0.72      0.73      0.73       320\n",
      "weighted avg       0.76      0.76      0.76       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9820a50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04919560956020364"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.72 * (1 - 0.72)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0606ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048643452796856425"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.73 * (1 - 0.73)) / len(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128c1ee",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e005b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d2a4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_clf = DecisionTreeClassifier().fit(train_feature_vector, train_text['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da05859",
   "metadata": {},
   "source": [
    "### Cross-Validation (Train Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4489c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_scores = []\n",
    "\n",
    "for train_index, val_index in kfold.split(train_text_processed):\n",
    "    \n",
    "    cross_train = train_text_processed.iloc[train_index].reset_index(drop = True)\n",
    "    cross_val = train_text_processed.iloc[val_index].reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    train_bow = bag_of_words_training(cross_train)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(cross_train['processed_wo_punct'])]\n",
    "    model = Doc2Vec(documents, vector_size = 100, window = 2, min_count = 1, workers = 4)\n",
    "    train_vectors = []\n",
    "    for text in cross_train['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        train_vectors.append(vector)\n",
    "    train_d2v = pd.DataFrame(train_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    train_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_train['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    train_sentiment['neg'] = neg_score\n",
    "    train_sentiment['neu'] = neu_score\n",
    "    train_sentiment['pos'] = pos_score\n",
    "    train_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_train = pd.concat([train_bow, train_d2v, train_sentiment], axis = 1)\n",
    "    features_train_vector = features_train.to_numpy()\n",
    "    \n",
    "    \n",
    "    test_bow = bag_of_words_testing(cross_val)\n",
    "    \n",
    "    test_vectors = []\n",
    "    for text in cross_val['processed_wo_punct']:\n",
    "        vector = model.infer_vector(text)\n",
    "        test_vectors.append(vector)\n",
    "    test_d2v = pd.DataFrame(test_vectors, columns=[f'w2v_{i}' for i in range(model.vector_size)])\n",
    "    \n",
    "    test_sentiment = pd.DataFrame()\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "    for text in cross_val['text']:\n",
    "        neg = sid.polarity_scores(text)['neg']\n",
    "        neg_score.append(neg)\n",
    "        neu = sid.polarity_scores(text)['neu']\n",
    "        neu_score.append(neu)\n",
    "        pos = sid.polarity_scores(text)['pos']\n",
    "        pos_score.append(pos)\n",
    "        compound = sid.polarity_scores(text)['compound']\n",
    "        compound_score.append(compound)\n",
    "    test_sentiment['neg'] = neg_score\n",
    "    test_sentiment['neu'] = neu_score\n",
    "    test_sentiment['pos'] = pos_score\n",
    "    test_sentiment['compound'] = compound_score\n",
    "    \n",
    "    features_test = pd.concat([test_bow, test_d2v, test_sentiment], axis = 1)\n",
    "    features_test_vector = features_test.to_numpy()\n",
    "    \n",
    "    model = DecisionTreeClassifier().fit(features_train_vector, cross_train['label'])\n",
    "    y_pred = model.predict(features_test_vector)\n",
    "    score = accuracy_score(cross_val['label'], y_pred)\n",
    "    \n",
    "    DT_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4ef3fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(DT_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15341444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029297312668570812"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((np.mean(DT_scores) * (1 - np.mean(DT_scores))) / len(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55871670",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d57939b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = DT_clf.predict(test_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a336ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_DT = DT_clf.score(test_feature_vector, test_text['label'])\n",
    "confusion_DT = confusion_matrix(test_text['label'], y_pred_DT)\n",
    "classification_DT = classification_report(test_text['label'], y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a0956dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2c397a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_DT_interval = 1.96 * sqrt((accuracy_DT * (1 - accuracy_DT)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e979b596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05329871918533198"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_DT_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3eaf56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 24  5]\n",
      " [31 98 34]\n",
      " [ 2 27 22]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d6d095f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.71       106\n",
      "           1       0.66      0.60      0.63       163\n",
      "           2       0.36      0.43      0.39        51\n",
      "\n",
      "    accuracy                           0.62       320\n",
      "   macro avg       0.57      0.59      0.58       320\n",
      "weighted avg       0.62      0.62      0.62       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e50ff825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053888862485675086"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.59 * (1 - 0.59)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d88d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054077888272379866"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.58 * (1 - 0.58)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91114233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05424412871454384"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * sqrt((0.57 * (1 - 0.57)) / len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5995ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "754f91d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11938379764249754"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_DT, p_DT = ttest_1samp(DT_scores, accuracy_DT)\n",
    "p_DT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
